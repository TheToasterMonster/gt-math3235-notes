\chapter{Events and Probabilities}

\section{Probability Spaces}

\begin{definition}
  A \emph{probability space} is a triple
  $(\Omega, \mathcal{F}, \mathbb{P})$
  where
  \begin{itemize}
    \item $\Omega$ is called the \emph{sample space}
      (the set of all possible
      outcomes of a random experiment);
    \item $\mathcal{F} \subseteq \mathcal{P}(\Omega)$,
      called the \emph{event space},\footnote{The elements of $\mathcal{F}$ are called \emph{events}. Events with cardinality 1 are called \emph{elementary}.} is nonempty
      and must satisfy:
      \begin{enumerate}[(i)]
        \item if $A \in \mathcal{F}$, then
          $A^c \in \mathcal{F}$,
        \item if $A_1, A_2, \dots \in \mathcal{F}$,
          then
          $\bigcup_{i=1}^\infty A_i \in \mathcal{F}$;
      \end{enumerate}
    \item $\mathbb{P}$ is a probabilty measure
      on $(\Omega, \mathcal{F})$ (to be defined later).
  \end{itemize}
\end{definition}

\begin{remark}
  In general, when $\Omega$ is finite or countably
  infinite, one takes
  $\mathcal{F} = \mathcal{P}(\Omega)$.
\end{remark}

\begin{prop}
  We always have $\varnothing, \Omega \in \mathcal{F}$.
\end{prop}

\begin{proof}
  Since $\mathcal{F} \ne \varnothing$, there
  exists some event $A \in \mathcal{F}$. Then we get $A^c \in \mathcal{F}$
  and $\Omega = A \cup A^c \in \mathcal{F}$
  by the complement and union properties of
  $\mathcal{F}$. Finally
  $\varnothing = \Omega^c \in \mathcal{F}$
  by the complement property.
\end{proof}

\begin{definition}
  A \emph{probability measure} on $(\Omega, \mathcal{F})$ is a function
  $\mathbb{P} : \mathcal{F} \to [0, \infty)$
  such that
  \begin{enumerate}[(i)]
    \item $\mathbb{P}(\Omega) = 1$,
    \item and $\mathbb{P}(\bigcup_{k = 1}^\infty A_k) = \sum_{k = 1}^\infty \mathbb{P}(A_k)$
      whenever $A_1, A_2, \dots \in \mathcal{F}$ are pairwise disjoint.\footnote{i.e. $A_i \cap A_j = \varnothing$ whenever $i \ne j$.}
  \end{enumerate}
\end{definition}

\begin{prop}
  The following properties hold for any
  probability measure $\mathbb{P}$ on
  $(\Omega, \mathcal{F})$:
  \begin{enumerate}[(1)]
    \item For any $A \in \mathcal{F}$,
      we have $\mathbb{P}(A^c) = 1 - \mathbb{P}(A)$.
    \item Let $A, B \in \mathcal{F}$ with
      $A \subseteq B$. Then $\mathbb{P}(A) \le \mathbb{P}(B)$.
    \item Let $A, B, C \in \mathcal{F}$. Then
      \[
        \PP(A \cup B) = \PP(A) + \PP(B) - \PP(A \cap B).
      \]
      This is the \emph{principle of inclusion-exclusion}.
  \end{enumerate}
\end{prop}

\begin{proof}
  $(1)$ Observe that $A \cup A^c = \Omega$ and
  $A \cap A^c = \varnothing$, so
  $1 = \mathbb{P}(\Omega) = \mathbb{P}(A \cup A^c) = \mathbb{P}(A) + \mathbb{P}(A^c)$.

  $(2)$ Write $B = A \cup (B \setminus A)$.\footnote{Note that $B \setminus A \in \mathcal{F}$ since $B \setminus A = B \cap A^c = (B^c \cup A)^c$.} Since
  $A \cap (B \setminus A) = \varnothing$,
  we have $\mathbb{P}(B) = \mathbb{P}(A) + \mathbb{P}(B \setminus A) \ge \mathbb{P}(A)$.\footnote{Since $\mathbb{P} : \mathcal{F} \to [0, \infty)$, we have $\mathbb{P}(B \setminus A) \ge 0$.}

  $(3)$ Left as an exercise. Follow similar ideas
  as in (2).
\end{proof}

\begin{remark}
  Observe that property (2) implies
  $\mathbb{P}(A) \le \mathbb{P}(\Omega) = 1$
  since any $A \subseteq \Omega$.
\end{remark}

\begin{example}
  Pick a point uniformly at random from the
  unit square $\Omega = [0, 1] \times [0, 1]$
  and record its coordinates. Then the probability 
  of the point being inside a fixed shape
  $S \subseteq \Omega$ is $|S|$, the area of $S$.
\end{example}

\begin{remark}
  Note that $\PP$ only satisfies
  \emph{countable} additivity. For instance let
  $\Omega = [0, 1]$ and $\PP$ be the uniform
  measure on $\Omega$. Then $\Omega = \bigcup_{x \in [0, 1]} \{x\}$
  and $\PP(\{x\}) = 0$ for every $x \in [0, 1]$,
    but $\PP(\Omega) = 1$.
    This is because the union
    $\bigcup_{x \in [0, 1]} \{x\}$ is uncountable.
\end{remark}

\begin{definition}
  Let $\Omega$ be finite and
  $\mathcal{F} = \mathcal{P}(\Omega)$. The uniform
  probability on $(\Omega, \mathcal{F})$
  is the one such that
  \[
    \mathbb{P}(\{\omega\}) = \frac{1}{\card \Omega}
    \quad \text{for all $\omega \in \Omega$.}
  \]
\end{definition}

\begin{prop}
  Let $\PP$ be the uniform probability
  on a finite set $\Omega$ and let $A \in \mathcal{F}$.
  Then
  \[
    \PP(A) = \frac{\card A}{\card \Omega}.
  \]
\end{prop}

\begin{proof}
  Note that $A$ is finite since $\Omega$ is and
  so we may enumerate its elements
  as $A = \{\omega_1, \omega_2, \dots, \omega_n\}$,
  where $n = \card A$.
  Then the sets $\{\omega_i\}_{i = 1}^n$ are pairwise disjoint
  and thus we have
  \[
    \PP(A) = \PP\left(\bigcup_{i = 1}^n \{\omega_i\}\right)
    = \sum_{i = 1}^n \PP(\{\omega_i\})
    = \sum_{i = 1}^n \frac{1}{\card \Omega}
    = \frac{n}{\card \Omega}
    = \frac{\card A}{\card \Omega},
  \]
  which is the desired result.
\end{proof}

\section{Conditional Probability}
\begin{definition}
  Let $B \in \mathcal{F}$ such that
  $\PP(B) > 0$. Then the \emph{conditional probability}
  of $A$ given $B$, written $\PP(A | B)$, is given by
  \[
    \PP(A | B) = \frac{\PP(A \cap B)}{\PP(B)}.
  \]
\end{definition}

\begin{remark}
  The intuition is that the extra information gained by
  knowing the occurrence of $B$ should update our
  computation of the probability of $A$.
\end{remark}

\begin{remark}
  Another way to think about conditional probability
  is a restriction of the sample space to $B$.
\end{remark}

\begin{example}
  Suppose a family has two children, one of
  which is a girl. What is the probability the other
  is a girl?
  Define the sample space to be
  \[
    \Omega = \{(B, G), (B, B), (G, G), (G, B)\}.
  \]
  Note that each elementary event is equally likely,
  i.e.
  \[
    \PP(\{(B, G)\}) = \PP(\{(G, B)\})
    = \PP(\{(B, B)\}) = \PP(\{(G, G)\}) = \frac{1}{4}.
  \]
  Let $A = \{\text{both of them are $G$}\} = \{(G, G)\}$
  and $B = \{\text{one is a girl}\} = \{(G, B), (B, G), (G, G)\}$.
  Then
  \[
    \PP(A | B) = \frac{\PP(A \cap B)}{\PP(B)}
    = \frac{\PP(\{(G, G)\})}{\PP(\{(G, B), (B, G), (G, G)\})}
    = \frac{1/4}{3/4} = \frac{1}{3}.
  \]
\end{example}

\begin{remark}
  If we instead condition on the event that one of
  them is a girl born on a Monday, then the
  probability changes! Carry out the calculation,
  and it should be $3 / 7$ for a
  $7$-day week.
\end{remark}

\begin{example}
  A drug test is 98\% accurate, i.e.
  a drug user tests positive 98\% of the time
  and a non-drug user tests negative 98\% of the time.
  Among a given
  population, it is known 2\% of people use drugs.
  Suppose I pick a person at random in the population
  and this person tests positive. What is the
  probability that the person is a drug
  user? Define the events
  \[
    A = \text{the person is a drug user}
    \quad \text{and} \quad
    B = \text{the person tests positive}.
  \]
  Then the goal is to compute $\PP(A | B)$. The
  98\% accuracy assumption implies that
  $\PP(B | A) = 0.98$. Now
  \[
    \PP(A | B) = \frac{\PP(A \cap B)}{\PP(B)}
    = \frac{\PP(B | A) \PP(A)}{\PP(B)}.
  \]
  Note that $B = (B \cap A) \cup (B \cap A^c)$
  and this is a disjoint union, so
  \begin{align*}
    \PP(B) = \PP(B \cap A) + \PP(B \cap A^c)
    &= \PP(B | A) \PP(A) \\
    + \PP(B | A^c) \PP(A^c)
    &= 0.98(0.02) + 0.02(0.98) = 2(0.98)(0.02).
  \end{align*}
  Here we noted that the 98\% accuracy of the test
  also implies that $\PP(B | A^c) = 0.02$.
  Thus we get
  \[
    \PP(A | B) = \frac{0.98(0.02)}{2(0.98)(0.02)}
    = \frac{1}{2}.
  \]
  Compute as an exercise that $\PP(A^c | B^c) = 0.996$.
\end{example}

\begin{remark}
  This test is designed clear non-drug users, not
  to identify drug users.
\end{remark}

\section{Bayes' Theorem}
\begin{definition}
  A \emph{partition} of $\Omega$ is a collection
  or sequence of events $\{B_k\}_{k = 1}^\infty$
  such that
  \[
    B_i \cap B_j = \varnothing
    \text{ for } i \ne j \quad \text{and} \quad
    \Omega = \bigcup_{k = 1}^\infty B_k.
  \]
\end{definition}

\begin{remark}
  For any event $A$, observe that
  \[
    A = A \cap \Omega
    = A \cap \left(\bigcup_{k = 1}^\infty B_k\right)
    = \bigcup_{k = 1}^\infty (A \cap B_k).
  \]
  Then we get
  \[
    \PP(A) = \PP\left(\bigcup_{k = 1}^\infty (A \cap B_k)\right)
    = \sum_{k = 1}^\infty \PP(A \cap B_k)
    = \sum_{k = 1}^\infty \PP(A | B_k) \PP(B_k).
  \]
  This is the \emph{partition theorem} in the book (Grimmett and Welsh).
  Now observe that
  \[
    \PP(B_i | A) = \frac{\PP(B_i \cap A)}{\PP(A)}
    = \frac{\PP(B_i \cap A)}{\sum_{k = 1}^\infty \PP(A| B_k)\PP(B_k)}
    = \frac{\PP(A | B_i) \PP(B_i)}{\sum_{k = 1}^\infty \PP(A| B_k)\PP(B_k)}
  \]
  for each $i = 1, 2, \dots$.
  This is \emph{Bayes' theorem}, which relates
  posterior probabilities to prior probabilities.
\end{remark}

\section{Conditional Independence}
\begin{prop}
  Let $B$ be such that $\PP(B) > 0$. Then
  $Q : \mathcal{F} \to [0, 1]$ given by
  $A \mapsto Q(A) = \PP(A | B)$ is a probability
  measure.
\end{prop}

\begin{proof}
  $(i)$ Observe that
  \[
    Q(\Omega) = \PP(\Omega | B)
    = \frac{\PP(\Omega \cap B)}{\PP(B)}
    = \frac{\PP(B)}{\PP(B)} = 1.
  \]

  $(ii)$ Let $\{A_k\}_{k = 1}^\infty \subseteq \mathcal{F}$
  be pairwise disjoint. Then observe that
  we have
  \begin{align*}
    Q\left(\bigcup_{k = 1}^\infty A_k\right)
    = \PP\left(\bigcup_{k = 1}^\infty A_k | B\right)
    &= \frac{\PP\left(\bigcup_{k = 1}^\infty (A_k \cap B)\right)}{\PP(B)} \\
    &= \frac{\sum_{k = 1}^\infty \PP(A_k \cap B)}{\PP(B)}
    = \sum_{k = 1}^\infty \PP(A_k | B)
    = \sum_{k = 1}^\infty Q(A_k).
  \end{align*}
  Thus $Q$ is indeed a probability measure.
\end{proof}

\begin{definition}
  Two events $A$ and $B$ are called
  \emph{independent}, written
  $A {\indep} B$, if
  $\PP(A \cap B) = \PP(A) \PP(B)$.
\end{definition}

\begin{example}
  Let $A, B$ be events with
  $\PP(A) = 0.6$ and $\PP(B) = 0.8$. Then
  $0.4 \le \PP(A \cap B) \le 0.6$.
  This is because $A \cap B \subseteq A$ implies
  $\PP(A \cap B) \le \PP(A) = 0.6$. Also noting
  that $A \cap B \subseteq \Omega$ and so
  $\PP(A \cap B) \le \PP(\Omega) = 1$ implies that
  \[
    \PP(A \cap B) = \PP(A) + \PP(B) - \PP(A \cup B)
    \ge 0.6 + 0.8 - 1 = 0.4.
  \]
  Note that if $A$ and $B$ were independent,
  then we can immediately conclude
  $\PP(A \cap B) = 0.6(0.8) = 0.48$.
\end{example}

\begin{prop}
  Assume $A$ and $B$ are events with
  $0 < \PP(A), \PP(B) < 1$.
  The following are equivalent:
  \begin{enumerate}
    \item $A$ and $B$ are independent,
    \item $\PP(A | B) = \PP(A)$,
    \item $\PP(B | A) = \PP(B)$,
    \item $\PP(A^c | B) = \PP(A^c)$,
    \item and $\PP(B^c | A) = \PP(B^c)$.
  \end{enumerate}
\end{prop}

\begin{proof}
  Note that $\PP(A | B) \PP(B) = \PP(A \cap B)$
  and $A {\indep} B$ if and only if
  $\PP(A \cap B) = \PP(A) \PP(B)$. Then
  use cancellation since $\PP(B) \ne 0$. Work
  out the rest as an exercise.
\end{proof}

\begin{definition}
  We say that three events $A, B, C$ are
  \emph{independent} if $A, B, C$ are pairwise
  independent\footnote{i.e. $\PP(X \cap Y) = \PP(X)\PP(Y)$ for any $X, Y \in \{A, B, C\}$.}
  and
  $\PP(A \cap B \cap C) = \PP(A) \PP(B) \PP(C)$.
\end{definition}

\begin{remark}
  Pairwise independence does not imply
  independence. Consider flipping a fair coin
  twice. Let
  \[
    A = \{\text{first flip is } T\}, \quad
    B = \{\text{second flip is } H\}, \quad
    C = \{\text{both flips are the same}\}.
  \]
  Then $A, B, C$ are pairwise independent but
  $\PP(A \cap B \cap C) = 0 \ne \PP(A) \PP(B) \PP(C) = 1 / 8$.
\end{remark}

\section{Homework Problems}

Problems \#1, 2, 9, 10, 14, 16, 17, 19 from Grimmett and Welsh.
